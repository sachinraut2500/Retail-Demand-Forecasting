# -*- coding: utf-8 -*-
"""Retail Demand Forecasting

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1a-DaSwyTIVpHrugM4-3iD72lN-5X1nEi
"""

# =========================
# requirements.txt
# =========================
pandas>=1.5.0
numpy>=1.24.0
scikit-learn>=1.1.0
xgboost>=1.7.0
prophet>=1.2.1
joblib
tqdm
matplotlib

# =========================
# src/__init__.py
# =========================
# empty

# =========================
# src/features.py
# =========================
from pathlib import Path
import pandas as pd
import numpy as np

def load_sales(path: Path) -> pd.DataFrame:
    df = pd.read_csv(path, parse_dates=["date"])
    required = {"date", "store", "item", "sales"}
    if not required.issubset(df.columns):
        raise ValueError(f"Missing columns: {required}")
    return df

def add_calendar_features(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df["day"] = df["date"].dt.day
    df["dayofweek"] = df["date"].dt.dayofweek
    df["weekofyear"] = df["date"].dt.isocalendar().week.astype(int)
    df["month"] = df["date"].dt.month
    df["quarter"] = df["date"].dt.quarter
    df["is_weekend"] = df["dayofweek"].isin([5,6]).astype(int)
    return df

def add_lag_features(df: pd.DataFrame, lags=[7,14,28]) -> pd.DataFrame:
    df = df.sort_values(["store","item","date"]).copy()
    for lag in lags:
        df[f"lag_{lag}"] = df.groupby(["store","item"])["sales"].shift(lag)
        df[f"rolling_mean_{lag}"] = (
            df.groupby(["store","item"])["sales"]
            .shift(1).rolling(window=lag).mean().reset_index(level=[0,1], drop=True)
        )
    return df

def preprocess_sales(input_csv: Path, out_csv: Path):
    df = load_sales(input_csv)
    df = add_calendar_features(df)
    df = add_lag_features(df)
    df = df.dropna().reset_index(drop=True)
    df.to_csv(out_csv, index=False)
    print(f"Wrote processed data to {out_csv}")

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("--input", required=True)
    parser.add_argument("--out", required=True)
    args = parser.parse_args()
    preprocess_sales(Path(args.input), Path(args.out))

# =========================
# src/train.py
# =========================
from pathlib import Path
import pandas as pd
import joblib
import json
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import xgboost as xgb
from datetime import datetime

MODEL_DIR = Path("models")
MODEL_DIR.mkdir(exist_ok=True)

def load_processed(path: Path) -> pd.DataFrame:
    return pd.read_csv(path, parse_dates=["date"])

def train_xgb(df: pd.DataFrame, features, target="sales", params=None):
    if params is None:
        params = dict(
            n_estimators=200, max_depth=6, learning_rate=0.1,
            objective="reg:squarederror", random_state=42
        )
    X, y = df[features], df[target]
    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, shuffle=False, random_state=42)
    model = xgb.XGBRegressor(**params)
    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=20, verbose=False)
    preds = model.predict(X_val)
    rmse = mean_squared_error(y_val, preds, squared=False)
    return model, rmse

def save_model(model, path: Path, metadata: dict):
    joblib.dump(model, path)
    with open(str(path) + ".meta.json", "w") as f:
        json.dump(metadata, f, indent=2)

def main(processed_csv: Path, out_model: Path):
    df = load_processed(processed_csv)
    features = [
        "day","dayofweek","weekofyear","month","quarter","is_weekend",
        "lag_7","lag_14","lag_28","rolling_mean_7","rolling_mean_14","rolling_mean_28"
    ]
    df = pd.get_dummies(df, columns=["store","item"], drop_first=True)
    feat_cols = features + [c for c in df.columns if c.startswith("store_") or c.startswith("item_")]
    model, rmse = train_xgb(df, feat_cols)
    metadata = {"trained_at": datetime.utcnow().isoformat() + "Z", "rmse_val": rmse, "features": feat_cols}
    save_model(model, out_model, metadata)
    print(f"Model saved to {out_model} (val RMSE={rmse:.4f})")

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("--processed", required=True)
    parser.add_argument("--out", default="models/xgb_model.joblib")
    args = parser.parse_args()
    main(Path(args.processed), Path(args.out))

# =========================
# src/predict.py
# =========================
from pathlib import Path
import pandas as pd
import joblib
import json

def load_model(path: Path):
    return joblib.load(path)

def predict(model, input_df: pd.DataFrame, feature_columns):
    preds = model.predict(input_df[feature_columns])
    out = input_df[["date","store","item"]].copy()
    out["predicted_sales"] = preds
    return out

def main(model_path: Path, input_csv: Path, out_csv: Path):
    model = load_model(model_path)
    df = pd.read_csv(input_csv, parse_dates=["date"])
    meta_path = Path(str(model_path) + ".meta.json")
    if meta_path.exists():
        meta = json.load(open(meta_path))
        feature_columns = meta.get("features", [])
    else:
        feature_columns = [c for c in df.columns if c not in ("date","sales")]
    preds = predict(model, df, feature_columns)
    preds.to_csv(out_csv, index=False)
    print(f"Predictions written to {out_csv}")

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("--model", required=True)
    parser.add_argument("--input", required=True)
    parser.add_argument("--out", default="preds.csv")
    args = parser.parse_args()
    main(Path(args.model), Path(args.input), Path(args.out))

# =========================
# src/evaluate.py
# =========================
from pathlib import Path
import pandas as pd
from sklearn.metrics import mean_squared_error

def mape(y_true, y_pred):
    return (abs((y_true - y_pred) / (y_true + 1e-9))).mean() * 100

def evaluate(actuals_csv: Path, preds_csv: Path):
    act = pd.read_csv(actuals_csv, parse_dates=["date"])
    pred = pd.read_csv(preds_csv, parse_dates=["date"])
    merged = act.merge(pred, on=["date","store","item"], how="inner")
    rmse = mean_squared_error(merged["sales"], merged["predicted_sales"], squared=False)
    mape_val = mape(merged["sales"], merged["predicted_sales"])
    print(f"RMSE={rmse:.4f}, MAPE={mape_val:.2f}%")
    return {"rmse": rmse, "mape": mape_val}

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("--actuals", required=True)
    parser.add_argument("--preds", required=True)
    args = parser.parse_args()
    evaluate(Path(args.actuals), Path(args.preds))